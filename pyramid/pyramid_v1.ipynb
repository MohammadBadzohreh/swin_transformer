{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torchvision.transforms as transforms\n",
    "from Utils.TinyImageNet_loader import get_tinyimagenet_dataloaders\n",
    "\n",
    "image_size =224\n",
    "tiny_transform_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize((image_size, image_size)), \n",
    "        transforms.RandomCrop(image_size, padding=5),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "tiny_transform_val = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "tiny_transform_test = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "train_loader, val_loader, test_loader = get_tinyimagenet_dataloaders(\n",
    "                                                    data_dir = '../datasets',\n",
    "                                                    transform_train=tiny_transform_train,\n",
    "                                                    transform_val=tiny_transform_val,\n",
    "                                                    transform_test=tiny_transform_test,\n",
    "                                                    batch_size=64,\n",
    "                                                    image_size=image_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride)\n",
    "        self.norm = nn.LayerNorm(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.norm(x)\n",
    "        return x, H, W\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, dim, mlp_ratio=4):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(dim * mlp_ratio)\n",
    "        self.fc1 = nn.Linear(dim, hidden_dim)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, sr_ratio=1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dim // num_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        self.q = nn.Linear(dim, dim)\n",
    "        self.kv = nn.Linear(dim, dim * 2)\n",
    "        self.sr_ratio = sr_ratio\n",
    "        if sr_ratio > 1:\n",
    "            self.sr = nn.Conv2d(dim, dim, kernel_size=sr_ratio, stride=sr_ratio)\n",
    "            self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x, H, W):\n",
    "        B, N, C = x.shape\n",
    "        q = self.q(x).reshape(B, N, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        if self.sr_ratio > 1:\n",
    "            x_ = x.permute(0, 2, 1).reshape(B, C, H, W)\n",
    "            x_ = self.sr(x_).reshape(B, C, -1).permute(0, 2, 1)\n",
    "            x_ = self.norm(x_)\n",
    "            kv = self.kv(x_).reshape(B, -1, 2, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
    "        else:\n",
    "            kv = self.kv(x).reshape(B, -1, 2, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
    "        k, v = kv[0], kv[1]\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        return x\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads, sr_ratio=1, mlp_ratio=4):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = Attention(dim, num_heads, sr_ratio)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.mlp = Mlp(dim, mlp_ratio)\n",
    "\n",
    "    def forward(self, x, H, W):\n",
    "        x = x + self.attn(self.norm1(x), H, W)\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class PVT224(nn.Module):\n",
    "    def __init__(self, num_classes=200):\n",
    "        super().__init__()\n",
    "        stage_cfgs = [[64, 1, 8, 2], [128, 2, 4, 2], [320, 5, 2, 2], [512, 8, 1, 2]]\n",
    "        self.patch_embed1 = PatchEmbed(3, 64, kernel_size=4, stride=4)\n",
    "        self.stages = nn.ModuleList()\n",
    "        self.patch_embeds = nn.ModuleList()\n",
    "        for i, (dim, heads, sr, blocks) in enumerate(stage_cfgs):\n",
    "            if i > 0:\n",
    "                self.patch_embeds.append(PatchEmbed(stage_cfgs[i-1][0], dim, kernel_size=2, stride=2))\n",
    "            stage = nn.Sequential(*[TransformerBlock(dim, heads, sr, mlp_ratio=4) for _ in range(blocks)])\n",
    "            self.stages.append(stage)\n",
    "        self.norm = nn.LayerNorm(stage_cfgs[-1][0])\n",
    "        self.head = nn.Linear(stage_cfgs[-1][0], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        x, H, W = self.patch_embed1(x)\n",
    "        for i, stage in enumerate(self.stages):\n",
    "            if i > 0:\n",
    "                x = x.permute(0, 2, 1).reshape(B, -1, H, W)\n",
    "                x, H, W = self.patch_embeds[i-1](x)\n",
    "            for blk in stage:\n",
    "                x = blk(x, H, W)\n",
    "        x = self.norm(x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# Training setup\n",
    "model = PVT224().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs=20):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "train(model, train_loader, val_loader, epochs=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
