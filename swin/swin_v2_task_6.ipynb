{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from einops import rearrange, reduce\n",
    "import os\n",
    "from timm.data import Mixup\n",
    "from timm.loss import SoftTargetCrossEntropy\n",
    "from timm.models.layers import DropPath\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from Utils.TinyImageNet_loader import get_tinyimagenet_dataloaders\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ------------------- Model Definition -------------------\n",
    "class HybridStem(nn.Module):\n",
    "    def __init__(self, in_ch=3, out_ch=48):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, groups=out_ch),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(out_ch, out_ch*2, 1),\n",
    "            nn.BatchNorm2d(out_ch*2),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.pool = nn.AvgPool2d(2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # 32x32\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)    # 16x16\n",
    "        return x\n",
    "\n",
    "class AdaptiveWindowAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads, window_range=(4,8)):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.window_range = window_range\n",
    "\n",
    "        self.ws_predictor = nn.Sequential(\n",
    "            nn.Linear(dim, dim//4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim//4, len(range(*window_range)))\n",
    "        )\n",
    "        \n",
    "        self.qkv = nn.Linear(dim, dim*3)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        \n",
    "    def get_window_size(self, x):\n",
    "        pooled = reduce(x, 'b h w c -> b c', 'mean')\n",
    "        logits = self.ws_predictor(pooled)\n",
    "        return torch.argmax(logits, dim=1) + self.window_range[0]\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, H, W, C = x.shape\n",
    "        # Get the predicted window size from the first sample\n",
    "        ws_pred = self.get_window_size(x)[0].item()\n",
    "        # All candidate window sizes in the specified range\n",
    "        ws_candidates = list(range(*self.window_range))\n",
    "        # Filter candidates that evenly divide H and W\n",
    "        valid_candidates = [ws for ws in ws_candidates if H % ws == 0 and W % ws == 0]\n",
    "        if valid_candidates:\n",
    "            # Choose the candidate closest to the predicted value\n",
    "            ws = min(valid_candidates, key=lambda x: abs(x - ws_pred))\n",
    "        else:\n",
    "            # If none of the candidates work, fall back to using H (assuming H==W)\n",
    "            ws = H\n",
    "        # Now ws divides H and W exactly, so reshape works correctly\n",
    "        x = x.view(B, H // ws, ws, W // ws, ws, C)\n",
    "        windows = rearrange(x, 'b h1 w1 h2 w2 c -> (b h1 w1) (h2 w2) c')\n",
    "        \n",
    "        qkv = self.qkv(windows).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.num_heads), qkv)\n",
    "        \n",
    "        attn = (q @ k.transpose(-2, -1)) * (C ** -0.5)\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        \n",
    "        x = (attn @ v).transpose(1, 2).reshape(B * (H // ws) * (W // ws), ws * ws, C)\n",
    "        x = self.proj(x)\n",
    "        \n",
    "        x = x.view(B, H // ws, W // ws, ws, ws, C)\n",
    "        x = rearrange(x, 'b h w ws1 ws2 c -> b (h ws1) (w ws2) c')\n",
    "        return x\n",
    "\n",
    "class SparseCrossAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads, sparse_ratio=0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.sparse_ratio = sparse_ratio\n",
    "        self.global_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.qkv = nn.Linear(dim, dim*3)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, H, W, C = x.shape\n",
    "        cls_token = self.global_token.expand(B, -1, -1)\n",
    "        local_feat = rearrange(x, 'b h w c -> b (h w) c')\n",
    "        combined = torch.cat([cls_token, local_feat], dim=1)\n",
    "        \n",
    "        qkv = self.qkv(combined).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.num_heads), qkv)\n",
    "        \n",
    "        scores = torch.norm(q, dim=-1)\n",
    "        _, idx = torch.topk(scores, k=int(scores.size(-1)*self.sparse_ratio), dim=-1)\n",
    "        \n",
    "        sparse_q = torch.gather(q, -2, idx.unsqueeze(-1).expand(-1, -1, -1, C//self.num_heads))\n",
    "        attn = (sparse_q @ k.transpose(-2, -1)) * (C ** -0.5)\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        \n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, -1, C)\n",
    "        x = self.proj(x)\n",
    "        return x[:, 0]\n",
    "\n",
    "\n",
    "class DWSSBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads, window_range, sparse_ratio=0.1, drop_path=0.):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.awa = AdaptiveWindowAttention(dim, num_heads, window_range)\n",
    "        self.sca = SparseCrossAttention(dim, num_heads, sparse_ratio)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, dim*4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim*4, dim)\n",
    "        )\n",
    "        # Projection to 128 dimensions so that all cls tokens match distillation target.\n",
    "        self.cls_proj = nn.Linear(dim, 128)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.drop_path(self.awa(self.norm1(x)))\n",
    "        cls_token = self.sca(self.norm2(x))\n",
    "        # Map cls token to common dimension (128)\n",
    "        cls_token = self.cls_proj(cls_token)\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x, cls_token\n",
    "\n",
    "class DWSS(nn.Module):\n",
    "    def __init__(self, num_classes=200):\n",
    "        super().__init__()\n",
    "        self.stem = HybridStem()\n",
    "        \n",
    "        # Stage 1\n",
    "        self.stage1 = nn.ModuleList([\n",
    "            DWSSBlock(96, 4, (4,6), 0.1) for _ in range(2)\n",
    "        ])\n",
    "        \n",
    "        # Stage 2\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(96, 128, 2, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        self.stage2 = nn.ModuleList([\n",
    "            DWSSBlock(128, 8, (6,8), 0.2) for _ in range(4)\n",
    "        ])\n",
    "        \n",
    "        # Stage 3\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 2, stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        self.stage3 = nn.ModuleList([\n",
    "            DWSSBlock(256, 16, (8,9), 0.3) for _ in range(2)\n",
    "        ])\n",
    "        \n",
    "        # Head\n",
    "        self.distill_token = nn.Parameter(torch.randn(1, 1, 256))\n",
    "        self.distill_head = nn.Linear(256, 128)\n",
    "        self.head = nn.Linear(256, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)  # [B, 96, 16, 16]\n",
    "        x = rearrange(x, 'b c h w -> b h w c')\n",
    "        \n",
    "        distill_loss = []\n",
    "        for blk in self.stage1:\n",
    "            x, cls = blk(x)\n",
    "            distill_loss.append(cls)\n",
    "        \n",
    "        x = rearrange(x, 'b h w c -> b c h w')\n",
    "        x = self.down1(x)\n",
    "        x = rearrange(x, 'b c h w -> b h w c')\n",
    "        \n",
    "        for blk in self.stage2:\n",
    "            x, cls = blk(x)\n",
    "            distill_loss.append(cls)\n",
    "        \n",
    "        x = rearrange(x, 'b h w c -> b c h w')\n",
    "        x = self.down2(x)\n",
    "        x = rearrange(x, 'b c h w -> b h w c')\n",
    "        \n",
    "        for blk in self.stage3:\n",
    "            x, cls = blk(x)\n",
    "            distill_loss.append(cls)\n",
    "        \n",
    "        # Distillation\n",
    "        distill_target = self.distill_head(self.distill_token.expand(x.size(0), -1, -1))\n",
    "        distill_loss = torch.stack([\n",
    "            F.kl_div(\n",
    "                F.log_softmax(d, dim=-1),\n",
    "                F.softmax(distill_target, dim=-1)\n",
    "            ) for d in distill_loss\n",
    "        ]).mean()\n",
    "        \n",
    "        # Classification\n",
    "        x = reduce(x, 'b h w c -> b c', 'mean')\n",
    "        return self.head(x), distill_loss\n",
    "\n",
    "# ------------------- Data Loading -------------------\n",
    "class TinyImageNet:\n",
    "    def __init__(self, root='./data', split='train', img_size=64):\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.data = torchvision.datasets.ImageFolder(\n",
    "            os.path.join(root, split), transform=self.transform)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "# ------------------- Training Utilities -------------------\n",
    "class EMA:\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        self.original = {}\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def apply(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.original[name] = param.data.clone()\n",
    "                param.data = self.shadow[name]\n",
    "\n",
    "    def update(self, model):\n",
    "        with torch.no_grad():\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n",
    "                    self.shadow[name] = new_average.clone()\n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion, ema, mixup_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        if mixup_fn is not None:\n",
    "            inputs, targets = mixup_fn(inputs, targets)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        outputs, distill_loss = model(inputs)\n",
    "        \n",
    "        if mixup_fn is not None:\n",
    "            loss = criterion(outputs, targets)\n",
    "        else:\n",
    "            loss = F.cross_entropy(outputs, targets)\n",
    "            \n",
    "        loss += 0.3 * distill_loss\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        ema.update(model)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        # Convert soft targets to hard labels if necessary\n",
    "        if targets.dim() > 1:\n",
    "            hard_targets = targets.argmax(dim=1)\n",
    "        else:\n",
    "            hard_targets = targets\n",
    "        total += hard_targets.size(0)\n",
    "        correct += predicted.eq(hard_targets).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100 * correct / total\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs, _ = model(inputs)\n",
    "        loss = F.cross_entropy(outputs, targets)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        # Convert soft targets to hard labels if necessary\n",
    "        if targets.dim() > 1:\n",
    "            hard_targets = targets.argmax(dim=1)\n",
    "        else:\n",
    "            hard_targets = targets\n",
    "        total += hard_targets.size(0)\n",
    "        correct += predicted.eq(hard_targets).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100 * correct / total\n",
    "\n",
    "# ------------------- Main Training Loop -------------------\n",
    "def main():\n",
    "    # Hard-coded hyperparameters and configurations\n",
    "    data_dir = './data'\n",
    "    epochs = 300\n",
    "    batch_size = 64  # Adjust as needed\n",
    "    lr = 2e-4\n",
    "    wd = 0.05\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    image_size = 224\n",
    "    tiny_transform_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize((image_size + 20, image_size + 20)),\n",
    "        transforms.RandomCrop(image_size, padding=8, padding_mode='reflect'),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), value='random'),\n",
    "    ])\n",
    "\n",
    "    tiny_transform_val = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "    train_loader, val_loader, test_loader = get_tinyimagenet_dataloaders(\n",
    "        data_dir='../datasets',\n",
    "        transform_train=tiny_transform_train,\n",
    "        transform_val=tiny_transform_val,\n",
    "        transform_test=tiny_transform_val,\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size\n",
    "    )\n",
    "\n",
    "    mixup_fn = Mixup(mixup_alpha=0.2, cutmix_alpha=1.0, prob=0.5, num_classes=200)\n",
    "\n",
    "    # Initialize model, optimizer, scheduler, loss function, and EMA\n",
    "    model = DWSS(num_classes=200).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    criterion = SoftTargetCrossEntropy() if mixup_fn is not None else nn.CrossEntropyLoss()\n",
    "    ema = EMA(model)\n",
    "    \n",
    "    best_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, optimizer, criterion, ema, mixup_fn, device\n",
    "        )\n",
    "        val_loss, val_acc = validate(model, val_loader, device)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_dwss.pth')\n",
    "    \n",
    "    print(f\"Best Validation Accuracy: {best_acc:.2f}%\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
